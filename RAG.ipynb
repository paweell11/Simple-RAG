{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bccf73b-e6ee-4579-8ea9-a1b5c4732d57",
   "metadata": {},
   "source": [
    "# **LOAD DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f727201-0488-48f4-ba93-6085976b80f5",
   "metadata": {},
   "source": [
    "**First, we need to load the dataset. I chose a small dataset from Wikipedia - specifically the \"rahular/simple-wikipedia\" dataset from HuggingFace Hub.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a034356b-5b3c-4f58-8f50-26339b0fa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rahular/simple-wikipedia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc85e0-f3f9-4fe3-bd29-05d819cac5d6",
   "metadata": {},
   "source": [
    "### **Key Information About Our Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39b2f2b-8578-4de8-a078-c7005b2ef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'datasets.dataset_dict.DatasetDict'>\n",
      "Available splits: ['train']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset type: {type(dataset)}\")\n",
    "print(f\"Available splits: {list(dataset.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e3fae8-20a1-4cd3-ba14-b8459f1cd54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 769764\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset length: {len(dataset[\"train\"])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2039b53a-0f4b-44af-ae10-f800c9abdaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features: {'text': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset features: {dataset['train'].features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46000122-29da-4301-b7ce-22b83b66e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample record (index 558): {'text': 'Plants are also multicellular eukaryotic organisms, but live by using light, water and basic elements to make their tissues.'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample record (index 558): {dataset['train'][558]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169c9d9b-9289-492a-8a51-c65df3f7efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty records: 0\n"
     ]
    }
   ],
   "source": [
    "empty = [i for i in range(len(dataset[\"train\"])) if not dataset[\"train\"][i][\"text\"].strip()]\n",
    "print(f\"Empty records: {len(empty)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5799db-2d66-4e84-a116-cee9441245a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data as DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April is the fourth month of the year, and com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April always begins on the same day of week as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April's flowers are the Sweet Pea and Daisy. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April comes between March and May, making it t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                              April\n",
       "1  April is the fourth month of the year, and com...\n",
       "2  April always begins on the same day of week as...\n",
       "3  April's flowers are the Sweet Pea and Daisy. I...\n",
       "4  April comes between March and May, making it t..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset[\"train\"][:5])\n",
    "print(\"Sample data as DataFrame:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebae6b4-a846-404a-bac7-a70d1e0fe764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245339ae-c122-4b25-85cf-bfd19322071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970cbc64-16b9-4fe4-879a-2c1699216353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4b1cb-d15e-4019-9038-5b8ba2fefe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f78c5a0-4764-42bf-82ed-3862c50c8a79",
   "metadata": {},
   "source": [
    "# **Document Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6718f04-76e9-4a82-a2c4-9f560290f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 769764 LangChain documents\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document as LangChainDocument\n",
    "    \n",
    "\n",
    "langchain_documents = []\n",
    "for i, record in enumerate(dataset[\"train\"]):\n",
    "    text_content = record[\"text\"]\n",
    "        \n",
    "    if not text_content.strip():\n",
    "        continue\n",
    "        \n",
    "    metadata = {\n",
    "        \"source\": \"simple_wikipedia\",\n",
    "        \"original_index\": i,\n",
    "        \"text_length\": len(text_content),\n",
    "    }\n",
    "        \n",
    "    doc = LangChainDocument(\n",
    "        page_content=text_content,\n",
    "        metadata=metadata\n",
    "    )\n",
    "        \n",
    "    langchain_documents.append(doc)\n",
    "    \n",
    "print(f\"✅ Created {len(langchain_documents)} LangChain documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f4ede-d4ad-4594-9c20-aefbb45ec326",
   "metadata": {},
   "source": [
    "# **Text Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1413594-99d7-41d6-a391-08a469793b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-empty documents: 769764\n",
      "\n",
      "DOCUMENT LENGTH STATISTICS (in characters):\n",
      "--------------------------------------------------\n",
      "Minimum length: 1 characters\n",
      "Maximum length: 10,570 characters\n",
      "Average length: 183 characters\n",
      "Median length: 127 characters\n",
      "Standard deviation: 198 characters\n",
      "\n",
      "Percentiles:\n",
      "  10th percentile: 12 characters\n",
      "  25th percentile: 24 characters\n",
      "  50th percentile: 127 characters\n",
      "  75th percentile: 271 characters\n",
      "  90th percentile: 432 characters\n",
      "  95th percentile: 558 characters\n",
      "  99th percentile: 872 characters\n"
     ]
    }
   ],
   "source": [
    "# Get all text lengths from the dataset\n",
    "text_lengths = []\n",
    "for i, record in enumerate(dataset[\"train\"]):\n",
    "    text = record[\"text\"]\n",
    "    if text.strip():  # Skip empty records\n",
    "        text_lengths.append(len(text))\n",
    "\n",
    "print(f\"Total non-empty documents: {len(text_lengths)}\")\n",
    "\n",
    "# =====================================================================\n",
    "# LENGTH STATISTICS\n",
    "# =====================================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nDOCUMENT LENGTH STATISTICS (in characters):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Minimum length: {min(text_lengths):,} characters\")\n",
    "print(f\"Maximum length: {max(text_lengths):,} characters\")\n",
    "print(f\"Average length: {np.mean(text_lengths):,.0f} characters\")\n",
    "print(f\"Median length: {np.median(text_lengths):,.0f} characters\")\n",
    "print(f\"Standard deviation: {np.std(text_lengths):,.0f} characters\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(f\"\\nPercentiles:\")\n",
    "for p in percentiles:\n",
    "    value = np.percentile(text_lengths, p)\n",
    "    print(f\"  {p}th percentile: {value:,.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f1a16-e948-4b90-8297-b4d1a30e290f",
   "metadata": {},
   "source": [
    "### Why Text Splitting is Not Necessary for Our Dataset\n",
    "\n",
    "After analyzing our Simple Wikipedia dataset, we found that text splitting (chunking) is not necessary for this particular dataset. Our dataset contains 769,764 non-empty documents with an average length of only 183 characters (46 tokens) and a median of 127 characters (32 tokens). Even the 95th percentile is just 558 characters (140 tokens), which is well below the typical embedding model limits of 512-8192 tokens.\n",
    "\n",
    "\n",
    "Since most embedding models can easily handle documents of this size, splitting our already short Wikipedia articles would actually be counterproductive. Text splitting is typically needed when documents are very long (>1000 characters) or exceed model token limits, but our dataset doesn't meet these criteria. Keeping the documents intact preserves the complete context of each Wikipedia article, results in better embeddings, and simplifies our RAG pipeline. We can proceed directly to embedding generation without any chunking steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b3fb2-1dcb-443f-849f-2cb099a8b7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d624cc-a023-402a-b953-c9f942f862e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004d71f7-c09d-4a2d-be58-06c985bbb5d8",
   "metadata": {},
   "source": [
    "# **Embedding Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0763f888-a240-44be-9c43-2f7633d91897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\",device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca9c02e-e04b-4ce1-b03b-1d6eea83c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (769764, 384)\n"
     ]
    }
   ],
   "source": [
    "texts = [doc.page_content for doc in langchain_documents]\n",
    "embeddings = embedding_model.encode(texts)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae88e9fb-cf26-415a-8b6f-fce0a4940455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarities = embedding_model.similarity(embeddings, embeddings)\n",
    "#print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384eea30-2d20-4d57-b220-0ed6c6407b6b",
   "metadata": {},
   "source": [
    "# PORÓB JAKIES POROWNAIA PODOBNYCH ZDAŃ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ee883-15ad-41c4-bb22-8db5e2dffda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ce21bd-7ca4-465d-95f7-c62721e525c2",
   "metadata": {},
   "source": [
    "# **Vector Database Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa2ce52-97e1-435f-a1da-59b9a6e2b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"simple_wikipedia_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_wikipedia_db\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dc5cf-7e91-4ab6-a14f-5247fa23b000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17a499aa-5b3a-4878-b440-2e42dfbe9f13",
   "metadata": {},
   "source": [
    "# **Retrieval System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8103d-efe3-4b9e-bd0a-6187e891081b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b852c-a733-41f9-97a3-dee889f6ab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0cbada-e9bb-4c0d-8cd9-4fe49ba00af9",
   "metadata": {},
   "source": [
    "# **Generation (LLM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c1cdc-aa84-4715-903e-e5076ffbb95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7cdeb-2f65-4e27-8417-2969b6df53c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d9bb9-87f4-4152-940b-3f7277c6eb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c12c0-c4e8-4418-aa0f-b2c0caa6df94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c43d2f-f5a5-4dd5-9d92-ea146e75f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4.43483-a187df25c\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.hip)  # sprawdza, czy ROCm jest dostępny\n",
    "print(torch.cuda.is_available())  # może też zadziałać z ROCm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "696f9a43-e525-4deb-bdb0-806421a2261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "890f6a50-5f69-4cd7-83b1-d2e5fa947f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: AMD Radeon RX 6750 XT\n",
      "PyTorch version: 2.9.0.dev20250715+rocm6.4\n"
     ]
    }
   ],
   "source": [
    "# Sprawdź szczegóły GPU\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0544479-1bfe-46ba-b952-5e3f28ff2456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
